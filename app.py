import streamlit as st
import pandas as pd
import plotly.express as px
import os
import numpy as np
import seaborn as sns
import plotly.graph_objects as go
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from scipy.stats import pearsonr, spearmanr

# TÃ­tulo do app
st.set_page_config(page_title="Painel de SaÃºde e PoluiÃ§Ã£o", layout="wide")
st.title("Painel Interativo: SaÃºde, PoluiÃ§Ã£o e Indicadores SocioeconÃ´micos")

# Carregar dados
@st.cache_data
def carregar_dados():
    df_curitiba = pd.read_csv("Base_Reduzida_Curitiba_PBI.csv")
    df_pg = pd.read_csv("Base_Reduzida_PBI_PontaGrossa.csv")
    df_medianeira = pd.read_csv("Base_Reduzida_PBI_Medianeira.csv")
    df_foz = pd.read_csv("Base_Reduzida_PBI_Foz.csv")
    df_se = pd.read_csv("Indicadores_Socioeconomicos_Cidades.csv")

    for df_cidade in [df_curitiba, df_pg, df_medianeira, df_foz]:
        if "CLUSTER" not in df_cidade.columns:
            variaveis = ["PM2_5", "INTERNACOES", "OBITOS", "CUSTO_MEDIO", "DURACAO_MEDIA", "UMIDADE", "TEMP_MEDIA"]
            df_tmp = df_cidade.dropna(subset=variaveis).copy()
            df_norm = StandardScaler().fit_transform(df_tmp[variaveis])
            kmeans = KMeans(n_clusters=3, random_state=42).fit(df_norm)
            df_cidade.loc[df_tmp.index, "CLUSTER"] = kmeans.labels_

    df_macro = pd.concat([df_curitiba, df_pg, df_medianeira, df_foz], ignore_index=True)

    # Cluster macro
    variaveis_macro = ["PM2_5", "INTERNACOES", "OBITOS", "CUSTO_MEDIO", "DURACAO_MEDIA", "UMIDADE", "TEMP_MEDIA"]
    df_macro_validos = df_macro.dropna(subset=variaveis_macro).copy()
    df_norm_macro = StandardScaler().fit_transform(df_macro_validos[variaveis_macro])
    kmeans_macro = KMeans(n_clusters=4, random_state=42).fit(df_norm_macro)
    df_macro.loc[df_macro_validos.index, "CLUSTER_MACRO"] = kmeans_macro.labels_

    # Merge socioeconÃ´mico
    df_macro = df_macro.merge(df_se, how="left", left_on="city", right_on="Cidade")

    # MÃ©tricas derivadas
    df_macro["RAZAO_INT_PM"] = df_macro["INTERNACOES"] / df_macro["PM2_5"]
    df_macro["RAZAO_OB_INT"] = df_macro["OBITOS"] / df_macro["INTERNACOES"]
    df_macro["CUSTO_PM"] = df_macro["CUSTO_MEDIO"] / df_macro["PM2_5"]
    df_macro["INT_PER_CAPITA"] = df_macro["INTERNACOES"] / df_macro["Densidade demogrÃ¡fica (hab/kmÂ²)"]

    # IVP (Ãndice de Vulnerabilidade Ã  PoluiÃ§Ã£o)
    df_norm_ivp = StandardScaler().fit_transform(df_macro[["PM2_5", "INTERNACOES", "IDHM (2010)", "Saneamento bÃ¡sico (%)"]].fillna(0))
    ivp = 0.4*df_norm_ivp[:,0] + 0.3*df_norm_ivp[:,1] - 0.2*df_norm_ivp[:,2] - 0.1*df_norm_ivp[:,3]
    df_macro["IVP"] = ivp

    return df_macro

df = carregar_dados()

# CriaÃ§Ã£o de dashboards por cidade
st.markdown("## Dashboards por Cidade")
cidade_sel = st.selectbox("Selecione uma cidade para visualizaÃ§Ã£o detalhada:", sorted(df["city"].unique()))
df_cidade = df[df["city"] == cidade_sel]

# MÃ©tricas principais por cidade
st.subheader(f"MÃ©tricas Principais - {cidade_sel}")
col1, col2, col3, col4 = st.columns(4)
col1.metric("PM2.5 MÃ©dio", f"{df_cidade['PM2_5'].mean():.1f} Âµg/mÂ³")
col2.metric("InternaÃ§Ãµes Totais", int(df_cidade["INTERNACOES"].sum()))
col3.metric("IVP MÃ©dio", f"{df_cidade['IVP'].mean():.2f}")
col4.metric("IDHM", f"{df_cidade['IDHM (2010)'].mean():.2f}")

# Radar por cidade
st.subheader("Radar das MÃ©tricas Derivadas")
cols = ["RAZAO_INT_PM", "RAZAO_OB_INT", "CUSTO_PM", "INT_PER_CAPITA", "IVP"]
df_radar = df.groupby("city")[cols].mean().reset_index()
df_melted = df_radar.melt(id_vars="city", var_name="MÃ©trica", value_name="Valor")
fig_radar = px.line_polar(df_melted[df_melted["city"] == cidade_sel], r="Valor", theta="MÃ©trica", line_close=True, title=f"Radar - {cidade_sel}")
st.plotly_chart(fig_radar, use_container_width=True)

# CorrelaÃ§Ã£o IVP vs Renda
st.subheader("CorrelaÃ§Ã£o IVP x Renda per Capita")
fig_scatter = px.scatter(df, x="Renda per capita (R$ mensais)", y="IVP", color="city", trendline="ols")
st.plotly_chart(fig_scatter, use_container_width=True)

# Heatmap de correlaÃ§Ã£o das mÃ©tricas por cidade
st.subheader("Heatmap de CorrelaÃ§Ã£o por Cidade")
df_corr = df[df["city"] == cidade_sel][cols + ["Renda per capita (R$ mensais)", "IDHM (2010)", "Saneamento bÃ¡sico (%)"]].corr()
fig_heat = px.imshow(df_corr, text_auto=True, color_continuous_scale="RdBu_r", title=f"CorrelaÃ§Ã£o - {cidade_sel}")
st.plotly_chart(fig_heat, use_container_width=True)

# AnÃ¡lises complementares jÃ¡ existentes
st.markdown("## Comparativos de MÃ©tricas Derivadas")
cols = ["RAZAO_INT_PM", "RAZAO_OB_INT", "CUSTO_PM", "INT_PER_CAPITA", "IVP"]
metric_titles = ["RazÃ£o InternaÃ§Ãµes / PM2.5", "RazÃ£o Ã“bitos / InternaÃ§Ãµes", "Custo MÃ©dio / PM2.5", "InternaÃ§Ãµes per Capita", "Ãndice de Vulnerabilidade Ã  PoluiÃ§Ã£o (IVP)"]
for col, title in zip(cols, metric_titles):
    st.subheader(title)
    fig = px.box(df, x="city", y=col, color="city", points="all", title=title)
    st.plotly_chart(fig, use_container_width=True)

st.markdown("## Ranking por Cidade (MÃ©dias das MÃ©tricas Derivadas)")
df_ranking = df.groupby("city")[cols].mean().reset_index().sort_values("IVP", ascending=False)
st.dataframe(df_ranking.style.format("{:.2f}"))




# TÃ­tulo do app
st.set_page_config(page_title="Painel de SaÃºde e PoluiÃ§Ã£o", layout="wide")
st.title("Painel Interativo: SaÃºde, PoluiÃ§Ã£o e Indicadores SocioeconÃ´micos")

# Carregar dados
@st.cache_data
def carregar_dados():
    df_curitiba = pd.read_csv("Base_Reduzida_Curitiba_PBI.csv")
    df_pg = pd.read_csv("Base_Reduzida_PBI_PontaGrossa.csv")
    df_medianeira = pd.read_csv("Base_Reduzida_PBI_Medianeira.csv")
    df_foz = pd.read_csv("Base_Reduzida_PBI_Foz.csv")
    df_se = pd.read_csv("Indicadores_Socioeconomicos_Cidades.csv")

    for df_cidade in [df_curitiba, df_pg, df_medianeira, df_foz]:
        if "CLUSTER" not in df_cidade.columns:
            variaveis = ["PM2_5", "INTERNACOES", "OBITOS", "CUSTO_MEDIO", "DURACAO_MEDIA", "UMIDADE", "TEMP_MEDIA"]
            df_tmp = df_cidade.dropna(subset=variaveis).copy()
            df_norm = StandardScaler().fit_transform(df_tmp[variaveis])
            kmeans = KMeans(n_clusters=3, random_state=42).fit(df_norm)
            df_cidade.loc[df_tmp.index, "CLUSTER"] = kmeans.labels_

    df_macro = pd.concat([df_curitiba, df_pg, df_medianeira, df_foz], ignore_index=True)

    # Cluster macro
    variaveis_macro = ["PM2_5", "INTERNACOES", "OBITOS", "CUSTO_MEDIO", "DURACAO_MEDIA", "UMIDADE", "TEMP_MEDIA"]
    df_macro_validos = df_macro.dropna(subset=variaveis_macro).copy()
    df_norm_macro = StandardScaler().fit_transform(df_macro_validos[variaveis_macro])
    kmeans_macro = KMeans(n_clusters=4, random_state=42).fit(df_norm_macro)
    df_macro.loc[df_macro_validos.index, "CLUSTER_MACRO"] = kmeans_macro.labels_

    # Merge socioeconÃ´mico
    df_macro = df_macro.merge(df_se, how="left", left_on="city", right_on="Cidade")

    # MÃ©tricas derivadas
    df_macro["RAZAO_INT_PM"] = df_macro["INTERNACOES"] / df_macro["PM2_5"]
    df_macro["RAZAO_OB_INT"] = df_macro["OBITOS"] / df_macro["INTERNACOES"]
    df_macro["CUSTO_PM"] = df_macro["CUSTO_MEDIO"] / df_macro["PM2_5"]
    df_macro["INT_PER_CAPITA"] = df_macro["INTERNACOES"] / df_macro["Densidade demogrÃ¡fica (hab/kmÂ²)"]

    # IVP (Ãndice de Vulnerabilidade Ã  PoluiÃ§Ã£o)
    df_norm_ivp = StandardScaler().fit_transform(df_macro[["PM2_5", "INTERNACOES", "IDHM (2010)", "Saneamento bÃ¡sico (%)"]].fillna(0))
    ivp = 0.4*df_norm_ivp[:,0] + 0.3*df_norm_ivp[:,1] - 0.2*df_norm_ivp[:,2] - 0.1*df_norm_ivp[:,3]
    df_macro["IVP"] = ivp

    return df_macro
    
@st.cache_data
def carregar_dados():
    df_curitiba = pd.read_csv("Base_Reduzida_Curitiba_PBI.csv")
    df_pg = pd.read_csv("Base_Reduzida_PBI_PontaGrossa.csv")
    df_medianeira = pd.read_csv("Base_Reduzida_PBI_Medianeira.csv")
    df_foz = pd.read_csv("Base_Reduzida_PBI_Foz.csv")
    df_se = pd.read_csv("Indicadores_Socioeconomicos_Cidades.csv")

    for df_cidade in [df_curitiba, df_pg, df_medianeira, df_foz]:
        if "CLUSTER" not in df_cidade.columns:
            variaveis = ["PM2_5", "INTERNACOES", "OBITOS", "CUSTO_MEDIO", "DURACAO_MEDIA", "UMIDADE", "TEMP_MEDIA"]
            df_tmp = df_cidade.dropna(subset=variaveis).copy()
            df_norm = StandardScaler().fit_transform(df_tmp[variaveis])
            kmeans = KMeans(n_clusters=3, random_state=42).fit(df_norm)
            df_cidade.loc[df_tmp.index, "CLUSTER"] = kmeans.labels_

    df_macro = pd.concat([df_curitiba, df_pg, df_medianeira, df_foz], ignore_index=True)

    # Cluster macro
    variaveis_macro = ["PM2_5", "INTERNACOES", "OBITOS", "CUSTO_MEDIO", "DURACAO_MEDIA", "UMIDADE", "TEMP_MEDIA"]
    df_macro_validos = df_macro.dropna(subset=variaveis_macro).copy()
    df_norm_macro = StandardScaler().fit_transform(df_macro_validos[variaveis_macro])
    kmeans_macro = KMeans(n_clusters=4, random_state=42).fit(df_norm_macro)
    df_macro.loc[df_macro_validos.index, "CLUSTER_MACRO"] = kmeans_macro.labels_

    # Merge socioeconÃ´mico
    df_macro = df_macro.merge(df_se, how="left", left_on="city", right_on="Cidade")

    return df_macro

df = carregar_dados()

# Filtros
cidades = df["city"].unique()
cidade_sel = st.selectbox("Selecione a cidade:", options=["Todas"] + sorted(list(cidades)))
df_filtro = df.copy()
if cidade_sel != "Todas":
    df_filtro = df[df["city"] == cidade_sel]

# Filtro por data
st.markdown("### Filtro por perÃ­odo")
data_min = pd.to_datetime(df_filtro["DATA_ENTRADA"].min())
data_max = pd.to_datetime(df_filtro["DATA_ENTRADA"].max())
data_sel = st.date_input("Selecione o intervalo de datas:", [data_min, data_max], min_value=data_min, max_value=data_max)
df_filtro = df_filtro[(pd.to_datetime(df_filtro["DATA_ENTRADA"]) >= pd.to_datetime(data_sel[0])) & (pd.to_datetime(df_filtro["DATA_ENTRADA"]) <= pd.to_datetime(data_sel[1]))]

# Tipo de cluster
cluster_tipo = st.radio("Tipo de clusterizaÃ§Ã£o:", ["Cluster por Cidade", "Cluster Macro"])
cluster_col = "CLUSTER" if cluster_tipo == "Cluster por Cidade" else "CLUSTER_MACRO"
clusters = df_filtro[cluster_col].dropna().unique()
cluster_opcoes = ["Todos"] + sorted([str(c) for c in clusters if pd.notnull(c)])
cluster_sel = st.selectbox("Selecione o cluster:", options=cluster_opcoes)
if cluster_sel != "Todos":
    df_filtro = df_filtro[df_filtro[cluster_col] == int(cluster_sel)]

# KPIs
col1, col2, col3, col4 = st.columns(4)
col1.metric("Total de InternaÃ§Ãµes", int(df_filtro["INTERNACOES"].sum()))
col2.metric("Total de Ã“bitos", int(df_filtro["OBITOS"].sum()))
col3.metric("PM2.5 MÃ©dio", f"{df_filtro['PM2_5'].mean():.1f} Âµg/mÂ³")
col4.metric("Umidade MÃ©dia", f"{df_filtro['UMIDADE'].mean():.1f}%")

col5, col6, col7, col8 = st.columns(4)
col5.metric("Custo MÃ©dio", f"R$ {df_filtro['CUSTO_MEDIO'].mean():,.2f}".replace(",", "X").replace(".", ",").replace("X", "."))
col6.metric("DuraÃ§Ã£o MÃ©dia", f"{df_filtro['DURACAO_MEDIA'].mean():.1f} dias")
col7.metric("Velocidade Vento MÃ©dia", f"{df_filtro['VEL_MEDIA'].mean():.1f} m/s")
col8.metric("Temperatura MÃ©dia", f"{df_filtro['TEMP_MEDIA'].mean():.1f} Â°C")

# KPIs SocioeconÃ´micos
st.markdown("### Indicadores SocioeconÃ´micos da Cidade")
if cidade_sel != "Todas":
    df_se_city = df[df["city"] == cidade_sel].iloc[0]
    col9, col10, col11 = st.columns(3)
    col9.metric("IDHM", df_se_city["IDHM (2010)"])
    col10.metric("Renda Per Capita (R$)", f"{df_se_city['Renda per capita (R$ mensais)']:.2f}")
    col11.metric("Taxa de AlfabetizaÃ§Ã£o (%)", f"{df_se_city['Taxa de alfabetizaÃ§Ã£o (%)']:.1f}%")

st.markdown("---")

# Comparativo entre cidades
st.markdown("### Comparativo entre Cidades - Indicadores SocioeconÃ´micos")
cols_se = ["IDHM (2010)", "Renda per capita (R$ mensais)", "Taxa de alfabetizaÃ§Ã£o (%)", "Taxa de urbanizaÃ§Ã£o (%)", "Densidade demogrÃ¡fica (hab/kmÂ²)", "Saneamento bÃ¡sico (%)"]
df_comp_se = df[["city"] + cols_se].drop_duplicates()
fig_se = px.bar(df_comp_se.melt(id_vars="city"), x="city", y="value", color="variable",
                barmode="group", title="ComparaÃ§Ã£o dos Indicadores SocioeconÃ´micos")
st.plotly_chart(fig_se, use_container_width=True)

# EstatÃ­sticas por cluster
df_stats = df.groupby(cluster_col)[["PM2_5", "INTERNACOES", "OBITOS", "CUSTO_MEDIO", "DURACAO_MEDIA", "UMIDADE", "TEMP_MEDIA"] + cols_se].mean().round(2)
st.markdown("### EstatÃ­sticas MÃ©dias por Cluster")
st.dataframe(df_stats)

# CorrelaÃ§Ã£o entre variÃ¡veis
st.markdown("### CorrelaÃ§Ã£o entre Indicadores de PoluiÃ§Ã£o, SaÃºde e SocioeconÃ´micos")
variaveis_corr = ["PM2_5", "INTERNACOES", "OBITOS", "CUSTO_MEDIO", "DURACAO_MEDIA", "UMIDADE", "TEMP_MEDIA"] + cols_se
df_corr = df[variaveis_corr].dropna()
corr_matrix = df_corr.corr(method="pearson")
fig_corr = px.imshow(corr_matrix, text_auto=True, title="Matriz de CorrelaÃ§Ã£o (Pearson)", aspect="auto")
st.plotly_chart(fig_corr, use_container_width=True)

# GrÃ¡ficos preservados
fig_series = px.line(df_filtro, x="DATA_ENTRADA", y="INTERNACOES", color="city", title="SÃ©rie Temporal de InternaÃ§Ãµes")
st.plotly_chart(fig_series, use_container_width=True)

fig_pm = px.line(df_filtro, x="DATA_ENTRADA", y="PM2_5", color="city", title="SÃ©rie Temporal de PM2.5")
st.plotly_chart(fig_pm, use_container_width=True)

fig_disp = px.scatter(df_filtro, x="PM2_5", y="INTERNACOES", color=cluster_col, title="DispersÃ£o PM2.5 vs InternaÃ§Ãµes")
st.plotly_chart(fig_disp, use_container_width=True)

if "lat" in df_filtro.columns and "long" in df_filtro.columns:
    fig_map = px.scatter_mapbox(df_filtro, lat="lat", lon="long", color=cluster_col,
                                 size="INTERNACOES", zoom=5,
                                 hover_name="city", hover_data=["PM2_5", "INTERNACOES"],
                                 mapbox_style="carto-positron", title="Mapa de InternaÃ§Ãµes e PoluiÃ§Ã£o")
    st.plotly_chart(fig_map, use_container_width=True)

# Mostrar link com ngrok
auth_token = os.environ.get("NGROK_AUTH_TOKEN")
if auth_token:
    from pyngrok import ngrok
    ngrok.set_auth_token(auth_token)
    public_url = ngrok.connect(8501)
    st.success(f"ðŸ”— Painel disponÃ­vel em: {public_url}")

